{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LN4rPyB7AvhP"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir(\"../\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.constants import TARGET, INIT, DATA_PATH, NUMERIC_FEATURES, TEST_IDS,DATA_PATH\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6F1fCkzvAogT",
        "outputId": "1eba0c9d-9f45-4603-9dda-fc1209cf2021"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "import pickle as pkl\n",
        "import numpy as np\n",
        "import logging\n",
        "import polars as pl\n",
        "\n",
        "logger = logging.getLogger()\n",
        "import sys\n",
        "from tqdm import tqdm\n",
        "\n",
        "logger.setLevel(logging.INFO)\n",
        "from tqdm import tqdm\n",
        "\n",
        "print(tf.__version__)\n",
        "print(tf.config.list_physical_devices(\"GPU\"))\n",
        "if tf.test.is_gpu_available():\n",
        "    print(\"TensorFlow está utilizando una GPU.\")\n",
        "    print(\"GPU utilizada:\", tf.test.gpu_device_name())\n",
        "else:\n",
        "    print(\"TensorFlow no está utilizando una GPU.\")\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "import joblib\n",
        "import gc\n",
        "import pickle as pkl\n",
        "from itertools import groupby"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pandas.core.arrays.timedeltas import timedelta\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.python.distribute.distribute_lib import def_function\n",
        "from math import sqrt,exp,pi, gamma"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WgfZjVjwAogT"
      },
      "source": [
        "## MODEL TARGET"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wqjzmlt7AogT"
      },
      "source": [
        "It is used as the target whether the subject is sleeping or not (1 if they are and 0 if not). There are series with events that have 'step=null'. In these series, there are chunks of data where it is unknown where the previous or next event is. These data points are labeled as 'nan', and will be used only as features since the loss function uses a mask to compute the loss only on data points that do not have a 'nan' target.\n",
        "\n",
        "Based on this target \"sleep\", events are constructed for evaluation and final submission using the 'get_event' function, which is being used in other notebooks.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.params import (\n",
        "    LEARNING_RATE,\n",
        "    STEPS_PER_EPOCH,\n",
        "    NUM_EPOCHS,\n",
        "    WARMUP_STEPS,\n",
        "    GPU_BATCH_SIZE,\n",
        "    SAMPLE_NORMALIZE,\n",
        "    DROP_INITIAL_DATE,\n",
        "    OPTMIZER_BETA1,\n",
        "    OPTMIZER_BETA2,\n",
        "    OPTMIZER_EPSILON,\n",
        "    ONLY_TEST,\n",
        "    FOLD,\n",
        "    TRAIN,\n",
        "    PREDICT,\n",
        "    CFG,\n",
        "    DIM,\n",
        ")\n",
        "from src.constants import NUMERIC_FEATURES,SIGMA\n",
        "train = TRAIN\n",
        "predict = PREDICT\n",
        "\n",
        "numeric_features = NUMERIC_FEATURES\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.utils import truncate_days,sample_normalize,drop_initial_date\n",
        "from src.distributions import gauss, gauss_standard, student_t, lognormal_standard, lognorm,student_t\n",
        "from src.data_processing import read_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZU6n5hD0AogV"
      },
      "source": [
        "####  GET AND BUILD DATA: Convert binary target in smooth distribution to train a nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QoKdzKg8AogW",
        "outputId": "fd389d16-4e2d-402a-9a1b-401d54b8d765"
      },
      "outputs": [],
      "source": [
        "\n",
        "events = pd.read_csv(os.path.join(DATA_PATH,f\"train_events.csv\"))\n",
        "events_check = pd.read_csv(os. path.join (DATA_PATH,f\"train_events.csv\")).dropna(\n",
        "    subset=\"timestamp\"\n",
        ")\n",
        "data = pd.read_parquet(\n",
        "    os.path.join(DATA_PATH,f\"data_train.parquet\"),\n",
        "    columns=[\"series_id\", \"step\", \"anglez\", \"enmo\", \"minute\", \"sine\", \"cosine\", \"sleep\", \"timestamp\"],\n",
        ").iloc[:1000]\n",
        "data[\"timestamp\"] = pd.to_datetime(data[\"timestamp\"])\n",
        "\n",
        "## train ids are mapped to int values so we need a dict to map back in the final part to comparare with the events dataset\n",
        "dict_ids = pkl.load(open(f\"{DATA_PATH}/dict_ids.pkl\", \"rb\"))\n",
        "\n",
        "targets, _, ids = joblib.load(f\"{DATA_PATH}/train_data.pkl\")\n",
        "targets = {dict_ids[ids[i]]: targets[i] for i in range(len(targets))}\n",
        "\n",
        "ids_ = np.load(f\"{DATA_PATH}/ids.npy\", allow_pickle=True).reshape(-1)\n",
        "fold_ids = pkl.load(open(f\"{DATA_PATH}/folds_ids.pkl\", \"rb\"))\n",
        "ids_=list(dict_ids.values())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-mGiWXH1ASoJ"
      },
      "outputs": [],
      "source": [
        "targets_events = targets\n",
        "series_ = gauss(n=SIGMA, sigma=SIGMA * 0.15)\n",
        "series_2 = gauss_standard(n=SIGMA, sigma=SIGMA * 0.15)\n",
        "series_t = student_t(n=SIGMA, v=0.5)\n",
        "series_lognorm = lognormal_standard()\n",
        "plt.scatter(range(len(series_)), series_)\n",
        "plt.scatter(range(len(series_t)), series_t, color=\"red\")\n",
        "plt.scatter(range(len(series_lognorm)), series_lognorm, color=\"orange\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Ahk8ljOp2Zy",
        "outputId": "a3077b79-06fc-4e14-e03f-ea5ff79188ba"
      },
      "outputs": [],
      "source": [
        "features, targets, descrp, steps_ = read_data(data, ids_,targets_events=targets_events,events_check=events_check,dict_ids=dict_ids)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pkl.dump(features, open(os.path.join(DATA_PATH,\"features.pkl\"), \"wb\"))\n",
        "pkl.dump(targets, open(os.path.join(DATA_PATH,\"targets.pkl\"), \"wb\"))\n",
        "pkl.dump(steps_, open(os.path.join(DATA_PATH,\"steps.pkl\"), \"wb\"))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "kagle",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
